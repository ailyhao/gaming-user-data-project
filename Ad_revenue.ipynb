{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import random\n",
    "import time\n",
    "from datetime import date, timedelta\n",
    "from pandas import DataFrame,Series\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "from dfply import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "df1 = pd.read_csv('gs://studentsmall/sep000000000000.csv')\n",
    "df2 = pd.read_csv('gs://studentsmall/sep000000000001.csv')\n",
    "df3 = pd.read_csv('gs://studentsmall/sep000000000002.csv')\n",
    "df4 = pd.read_csv('gs://studentsmall/sep000000000003.csv')\n",
    "df5 = pd.read_csv('gs://studentsmall/sep000000000004.csv')\n",
    "df6 = pd.read_csv('gs://studentsmall/sep000000000005.csv')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "df = pd.DataFrame(np.concatenate([df1.values, df2.values, df3.values, df4.values, df5.values ,df6.values]), columns=df1.columns)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_users = df['userID'].nunique()\n",
    "total_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caculate userAge, which is how many days the event happened since gaUserStartDate\n",
    "start_time = time.time()\n",
    "data['eventTimestamp'] = pd.to_datetime(data['eventTimestamp'])\n",
    "data['gaUserStartDate'] = pd.to_datetime(data['gaUserStartDate'])\n",
    "data['userAge'] = (data['eventTimestamp'] - data['gaUserStartDate']).dt.days\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userID_uni = data['userID'].unique()\n",
    "userID_uni = pd.DataFrame(userID_uni, columns = ['userID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "total_result = {}\n",
    "day_cases = [3, 7, 20, 30]\n",
    "\n",
    "for day_case in day_cases:\n",
    "    day = data[(data['userAge'] <= day_case) & (data['gaUserStartDate'] >= min(data['eventTimestamp']))]\n",
    "    print(len(day), day_case)\n",
    "\n",
    "    # countAdImpression: select 'adImpression' from eventName, and then count rows grouping by userID\n",
    "    impression_day = day[day['eventName'] == 'adImpression'][['userID', 'eventName','action']]\n",
    "    userID_impression_day = impression_day.groupby('userID').size()\n",
    "    userID_impression_day = pd.DataFrame(userID_impression_day,columns = ['countAdImpression'])\n",
    "\n",
    "    # countAdClicked: select 'adImpression' from eventName and 'clicked' from action, then count rows grouping by userID\n",
    "    impression_click_day = day[(day['eventName'] == 'adImpression') & (day['action'] == 'clicked')][['userID', 'eventName','action']]\n",
    "    userID_impression_click_day = impression_click_day.groupby('userID').size()\n",
    "    userID_impression_click_day = pd.DataFrame(userID_impression_click_day,columns = ['countAdClicked'])\n",
    "\n",
    "    # missionTime: select 'missionCompleted' from eventName, then sum time\n",
    "    missionTime_raw_day = day[(day['eventName'] == 'missionCompleted')][['userID', 'time']]\n",
    "    missionTime_day = missionTime_raw_day.groupby('userID').sum()\n",
    "    missionTime_day = missionTime_day.rename(columns = {'time': 'missionTime'})\n",
    "\n",
    "    # CountMission = select 'missionCompleted'from eventName, then count rows\n",
    "    missionCount_day = missionTime_raw_day.groupby('userID').size()\n",
    "    missionCount_day = pd.DataFrame(missionCount_day, columns=['CountMission'])\n",
    "    \n",
    "    # timePerMission\n",
    "    userID_timePerMission_day = pd.merge(missionTime_day,missionCount_day, on='userID')\n",
    "    userID_timePerMission_day['timePerMission']= userID_timePerMission_day['missionTime']/userID_timePerMission_day['CountMission']\n",
    "    \n",
    "    # dailyMissionTime = select \"dailyMissionCompleted\" from eventName, then sum time\n",
    "    dailyMissionTime_raw_day = day[(day['eventName'] == 'dailyMissionCompleted')][['userID', 'time']]\n",
    "    dailyMissionTime_day = dailyMissionTime_raw_day.groupby('userID').sum()\n",
    "    dailyMissionTime_day = dailyMissionTime_day.rename(columns = {'time': 'dailyMissionTime'})\n",
    "    \n",
    "    # CountDailyMission = select \"dailyMissionCompleted\" from eventName, then count rows\n",
    "    dailyMissionCount_day = dailyMissionTime_raw_day.groupby('userID').size()\n",
    "    dailyMissionCount_day = pd.DataFrame(dailyMissionCount_day, columns=['CountDailyMission'])\n",
    "    \n",
    "    # timePerDailyMission\n",
    "    timePerDailyMission_day = pd.merge(dailyMissionTime_day,dailyMissionCount_day, on='userID')\n",
    "    timePerDailyMission_day['timePerDailyMission']= dailyMissionTime_day['dailyMissionTime']/dailyMissionCount_day['CountDailyMission']\n",
    "     \n",
    "    # totalHintsUsed: select 'missionCompleted' or 'dailyMissionCompleted' from eventName, then sum hintUsed\n",
    "    hint_day = day[(day['eventName'] == 'missionCompleted')][['userID', 'hintsUsed']]\n",
    "    totalHint_day = hint_day.groupby('userID').sum()\n",
    "\n",
    "    # hintPerMission: totalHintsUsed/CountMission\n",
    "    hintPerMission_day = pd.merge(totalHint_day,missionCount_day, on='userID')\n",
    "    hintPerMission_day['hintsPerMission'] = hintPerMission_day['hintsUsed']/hintPerMission_day['CountMission']\n",
    "    hintPerMission_day = hintPerMission_day.drop(columns = ['CountMission'])\n",
    "    \n",
    "    # Level reached at end of the day case\n",
    "    level_day = day.groupby(['userID'])['userLevel'].max()\n",
    "    level_day = pd.DataFrame(level_day, columns = ['userLevel'])\n",
    "    \n",
    "    # hintPerLevel\n",
    "    hintPerLevel_day = pd.merge(totalHint_day,level_day, on='userID')\n",
    "    hintPerLevel_day['hintsPerLevel'] = hintPerLevel_day['hintsUsed']/hintPerLevel_day['userLevel']\n",
    "    hintPerLevel_day = hintPerLevel_day.drop(columns = ['hintsUsed'])\n",
    "    \n",
    "    # countSpecialOffer: select 'specialOffer' from eventName, then count rows\n",
    "    speOffer_day = day[(day['eventName'] == 'specialOffer')]\n",
    "    speoffer_count_day = speOffer_day.groupby('userID').size()\n",
    "    speoffer_count_day = pd.DataFrame(speoffer_count_day,columns = ['countSpeOffer'])\n",
    "\n",
    "    # countSpecialOfferAccept: select 'specialOffer' from eventName and 'accepted' from action, and then count rows \n",
    "    SpeOffer_accept_day = day[(day['eventName'] == 'specialOffer') & (day['action'] == 'accepted')]\n",
    "    SpeOffer_accept_day = SpeOffer_accept_day.groupby('userID').size()\n",
    "    SpeOffer_accept_day = pd.DataFrame(SpeOffer_accept_day,columns = ['countSpeOfferAccept'])\n",
    "    \n",
    "    # totalDuplicateWords: select 'missionCompleted' or 'dailyMissionCompleted' from eventName, and then sum duplicateWords\n",
    "    # grouping by userID\n",
    "    DuplicateWords_raw = day[day['eventName'] == 'missionCompleted'][['userID','duplicateWords']]\n",
    "    DuplicateWords = DuplicateWords_raw.groupby('userID').sum()\n",
    "\n",
    "    # duplicateWordsPerMis: duplicateWords/CountMission\n",
    "    DuplicateWordsPerMis = pd.merge(DuplicateWords,missionCount_day, on='userID')\n",
    "    DuplicateWordsPerMis['duplicateWordsPerMis'] = DuplicateWordsPerMis['duplicateWords']/DuplicateWordsPerMis['CountMission']\n",
    "    DuplicateWordsPerMis = DuplicateWordsPerMis.drop(columns = ['CountMission'])\n",
    "    \n",
    "    # totalExtraWords: select 'missionCompleted' from eventName, and then sum extraWords\n",
    "    # grouping by userID\n",
    "    ExtraWords_raw = day[day['eventName'] == 'missionCompleted'][['userID','extraWords']]\n",
    "    ExtraWords = ExtraWords_raw.groupby('userID').sum()\n",
    "\n",
    "    # extraWordsPerMis: totalExtraWords/CountMission\n",
    "    extraWordsPerMis = pd.merge(ExtraWords,missionCount_day, on='userID')\n",
    "    extraWordsPerMis['extraWordsPerMis'] = extraWordsPerMis['extraWords']/extraWordsPerMis['CountMission']\n",
    "    extraWordsPerMis = extraWordsPerMis.drop(columns = ['CountMission'])\n",
    "    \n",
    "    # totalInvalidWords: select 'missionCompleted' from eventName, and then sum invalidWords\n",
    "    InvalidWords_raw = day[day['eventName'] == 'missionCompleted'][['userID','invalidWords']]\n",
    "    InvalidWords = InvalidWords_raw.groupby('userID').sum()\n",
    "\n",
    "    # invalidWordsPerMis\n",
    "    InvalidWordsPerMis = pd.merge(InvalidWords,missionCount_day, on='userID')\n",
    "    InvalidWordsPerMis['invalidWordsPerMis'] = InvalidWordsPerMis['invalidWords']/InvalidWordsPerMis['CountMission']\n",
    "    InvalidWordsPerMis = InvalidWordsPerMis.drop(columns = ['CountMission'])\n",
    "    \n",
    "    # playerIQ: select 'missionCompleted' or 'dailyMissionCompleted' from eventName, and then sum playerIQ\n",
    "    # grouping by userID\n",
    "    playerIQ_raw = day[(day['eventName'] == 'missionCompleted')|(day['eventName'] == 'dailyMissionCompleted')][['userID','playerIQ']]\n",
    "    playerIQ = playerIQ_raw.groupby('userID').sum()\n",
    "\n",
    "    \n",
    "    # push: select out \"gameStarted\" from eventName, find the push status when eventTimestamp = max(eventTimestamp) \n",
    "    # grouping by each user\n",
    "    push_raw = day[day['eventName'] == 'gameStarted'][['userID','push','eventTimestamp']]\n",
    "    push = push_raw.loc[push_raw.groupby(\"userID\")[\"eventTimestamp\"].idxmax()]\n",
    "    push = push.drop(columns = ['eventTimestamp']).set_index('userID') \n",
    "    \n",
    "    # total shuffles: select missionCompleted and sum shuffles\n",
    "    # shuffle per mission: total shuffles/CountMission\n",
    "    totalShuffles = day[(day['eventName']=='missionCompleted')].groupby(['userID']).agg({'missionName':'nunique','shuffles':'sum'})\n",
    "    totalShuffles['shufflesPerMission']=totalShuffles['shuffles'].div(totalShuffles['missionName'])\n",
    "    shuffles = totalShuffles.drop(columns = ['missionName'])\n",
    "    \n",
    "    \n",
    "    # building userprofile through acquisitionchannel,platform,\n",
    "    user_profile=(day >> select('userID','gaUserAcquisitionChannel','platform') >> group_by('userID')).drop_duplicates()\n",
    "    user_profile = user_profile[user_profile.gaUserAcquisitionChannel != \"None\"]\n",
    "    user_profile = user_profile.drop_duplicates(subset='userID', keep=\"first\").set_index('userID')\n",
    "    \n",
    "    # user removedAds \n",
    "    user_removedAds_raw = day[day['eventName'] == 'gameStarted'][['userID','removedAds','eventTimestamp']]\n",
    "    user_removedAds = user_removedAds_raw.loc[user_removedAds_raw.groupby(\"userID\")[\"eventTimestamp\"].idxmax()]\n",
    "    user_removedAds = user_removedAds.drop(columns = ['eventTimestamp']).set_index('userID') \n",
    "    \n",
    "    # countVideoOffer: select 'videoOffer' from eventName and corresponding action, then count rows\n",
    "    vidOffer_cvv = day[(day['eventName'] == 'videoOffer') & (day['action'] == 'CVV')]\n",
    "    vidOffer_cvv_count = vidOffer_cvv.groupby('userID').size()\n",
    "    vidOffer_cvv_count = pd.DataFrame(vidOffer_cvv_count, columns = ['countCVV'])\n",
    "    \n",
    "    vidOffer_no = day[(day['eventName'] == 'videoOffer') & (day['action'] == 'NO')]\n",
    "    vidOffer_no_count = vidOffer_no.groupby('userID').size()\n",
    "    vidOffer_no_count = pd.DataFrame(vidOffer_no_count, columns = ['countNO'])\n",
    "    \n",
    "    vidOffer_noCmplt = day[(day['eventName'] == 'videoOffer') & (day['action'] == 'NOTCOMPLETED')]\n",
    "    vidOffer_noCmplt_count = vidOffer_noCmplt.groupby('userID').size()\n",
    "    vidOffer_noCmplt_count = pd.DataFrame(vidOffer_noCmplt_count, columns = ['countNoCmplt'])\n",
    "    \n",
    "    # lifespan\n",
    "    user_lifespan=(day >> select('userID','userAge') >> group_by('userID') >> summarize(Lifespan=X.userAge.max()))\n",
    "    \n",
    "    # adRevenue for ad impressions and video offers\n",
    "    total_adRevenue = (day >> select('userID','almaxRevenue') >> group_by('userID') >> summarize(ad_Rev=X.almaxRevenue.sum()))\n",
    "    adImpression_revenue = (day >> select('userID','almaxRevenue', 'almaxAdUnitType') >>  mask(X.almaxAdUnitType == 'BANNER') >> group_by('userID') >> summarize(adImpression_Rev=X.almaxRevenue.sum()))\n",
    "    videoOffer_revenue = (day >> select('userID','almaxRevenue', 'almaxAdUnitType') >>  mask((X.almaxAdUnitType == 'INTER') |  (X.almaxAdUnitType == 'REWARD')) >> group_by('userID') >> summarize(videoOffer_Rev=X.almaxRevenue.sum()))\n",
    "\n",
    "    # merge into one dataframe\n",
    "    agg_data = pd.merge(userID_uni,userID_impression_day,on='userID', how='left')\n",
    "    agg_data = pd.merge(agg_data, userID_impression_click_day, on='userID', how='left')\n",
    "    agg_data = pd.merge(agg_data, userID_timePerMission_day, on='userID', how='left')\n",
    "    agg_data = pd.merge(agg_data, timePerDailyMission_day, on='userID', how= 'left')\n",
    "    agg_data = pd.merge(agg_data, hintPerMission_day, on='userID', how='left')\n",
    "    agg_data = pd.merge(agg_data, hintPerLevel_day, on= 'userID', how='left')\n",
    "    agg_data = pd.merge(agg_data, speoffer_count_day, on='userID', how='left')\n",
    "    agg_data = pd.merge(agg_data, SpeOffer_accept_day, on='userID', how='left')\n",
    "    agg_data = pd.merge(agg_data, DuplicateWordsPerMis, on='userID', how='left')\n",
    "    agg_data = pd.merge(agg_data, extraWordsPerMis, on='userID', how='left')\n",
    "    agg_data = pd.merge(agg_data, InvalidWordsPerMis, on='userID', how='left')\n",
    "    agg_data = pd.merge(agg_data, playerIQ, on='userID', how='left')\n",
    "    agg_data = pd.merge(agg_data, push, on='userID', how='left')\n",
    "    agg_data = pd.merge(agg_data, shuffles, on='userID', how='left')\n",
    "    agg_data = pd.merge(agg_data, user_profile, on='userID', how='left')\n",
    "    agg_data = pd.merge(agg_data, user_removedAds, on='userID', how='left')\n",
    "    agg_data = pd.merge(agg_data, vidOffer_cvv_count, on='userID', how='left')\n",
    "    agg_data = pd.merge(agg_data, vidOffer_no_count, on='userID', how='left')\n",
    "    agg_data = pd.merge(agg_data, vidOffer_noCmplt_count, on='userID', how='left')\n",
    "    agg_data = pd.merge(agg_data, user_lifespan, on='userID', how='left')\n",
    "    agg_data = pd.merge(agg_data, total_adRevenue, on='userID', how='left')\n",
    "    agg_data = pd.merge(agg_data, adImpression_revenue, on='userID', how='left')\n",
    "    agg_data = pd.merge(agg_data, videoOffer_revenue, on='userID', how='left')\n",
    "    \n",
    "    total_result[day_case] = agg_data\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_result[3].head()\n",
    "## most of nulls could be filled with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the final dataframe for data from day0 to day3 after dropping rows with NaN in all columns\n",
    "var = total_result[3]\n",
    "var.set_index('userID', inplace = True)\n",
    "var.dropna(axis=0, how='all', thresh=None, subset=None, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = var.dropna(subset = ['gaUserAcquisitionChannel', 'platform'])\n",
    "var.fillna(0 , inplace = True)\n",
    "var.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userNoRev = var[(var['removedAds']==0) & (var['ad_Rev'] == 0)].index\n",
    "var.drop(userNoRev, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_heatmap = var.drop(columns = ['gaUserAcquisitionChannel', 'platform'])\n",
    "f, ax = plt.subplots(figsize=(20, 16))\n",
    "corr = var_heatmap.corr()\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_var = var.drop(columns = ['gaUserAcquisitionChannel', 'platform'])\n",
    "removeAds_players = kmeans_var[kmeans_var['removedAds']==1]\n",
    "#kmeans_var[\"Ad_Impression_Value\"] = 4*(kmeans_var['countAdImpression'] - kmeans_var['countAdClicked']) + 10*kmeans_var['countAdClicked']\n",
    "kmeans_var = kmeans_var.drop(columns = ['countAdImpression', 'countAdClicked','timePerMission','timePerDailyMission','hintsPerMission',\n",
    "                                        'timePerDailyMission','hintsPerLevel','duplicateWordsPerMis','extraWordsPerMis','invalidWordsPerMis',\n",
    "                                      'shufflesPerMission','removedAds', 'countCVV', 'countNO', 'countNoCmplt', 'ad_Rev', 'adImpression_Rev', 'videoOffer_Rev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_var = kmeans_var[kmeans_var.userLevel != 0]\n",
    "kmeans_var.to_csv('kmeans_var.csv')\n",
    "kmeans_var_array = kmeans_var.to_numpy()\n",
    "scaler = MinMaxScaler()\n",
    "kmeans_var_array = scaler.fit_transform(kmeans_var_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_var_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_var.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Error =[]\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters = i).fit(kmeans_var_array)\n",
    "    kmeans.fit(kmeans_var_array)\n",
    "    Error.append(kmeans.inertia_)\n",
    "\n",
    "    \n",
    "fig = plt.figure()\n",
    "plt.plot(range(1, 11), Error)\n",
    "plt.title('Elbow method')\n",
    "plt.xlabel('No of clusters')\n",
    "plt.ylabel('Error')\n",
    "plt.show()\n",
    "fig.savefig(\"ElbowCurve.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build k-means clustering model with 4 clusters\n",
    "kmeans4 = KMeans(n_clusters=4,random_state=40)\n",
    "y_kmeans4 = kmeans4.fit_predict(kmeans_var_array)\n",
    "print(y_kmeans4)\n",
    "\n",
    "kmeans4.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(kmeans_var.columns)):\n",
    "    for n in range(0,4):\n",
    "        print(kmeans_var.columns[i], \", cluster: \", n)\n",
    "        print(\"Center: \", kmeans4.cluster_centers_[n][i])\n",
    "        print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(kmeans_var.columns)):\n",
    "    print(str(kmeans_var.columns[i]) + ' ' +str(kmeans4.cluster_centers_[1][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_var.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 4 clusters\n",
    "for i in range(0,len(kmeans_var.columns)):\n",
    "    plt.scatter(\n",
    "        kmeans_var_array[y_kmeans4 == 0, i], kmeans_var_array[y_kmeans4 == 0, 1],\n",
    "        s=50, c='lightgreen',\n",
    "        marker='s', edgecolor='black',\n",
    "        label='cluster 0'\n",
    "    )\n",
    "\n",
    "    plt.scatter(\n",
    "        kmeans_var_array[y_kmeans4 == 1, i], kmeans_var_array[y_kmeans4 == 1, 1],\n",
    "        s=50, c='orange',\n",
    "        marker='o', edgecolor='black',\n",
    "        label='cluster 1'\n",
    "    )\n",
    "\n",
    "    plt.scatter(\n",
    "        kmeans_var_array[y_kmeans4 == 2, i], kmeans_var_array[y_kmeans4 == 2, 1],\n",
    "        s=50, c='lightblue',\n",
    "        marker='v', edgecolor='black',\n",
    "        label='cluster 2'\n",
    "    )\n",
    "\n",
    "    plt.scatter(\n",
    "        kmeans_var_array[y_kmeans4 == 3, i], kmeans_var_array[y_kmeans4 == 3, 1],\n",
    "        s=50, c='red',\n",
    "        marker='.', edgecolor='black',\n",
    "        label='cluster 3'\n",
    "    )\n",
    "\n",
    "#    plot the centroids\n",
    "    plt.scatter(\n",
    "        kmeans4.cluster_centers_[:, i], kmeans4.cluster_centers_[:, 1],\n",
    "        s=250, marker='*',\n",
    "        c='red', edgecolor='black',\n",
    "        label='centroids'\n",
    "    )\n",
    "    plt.legend(scatterpoints=1)\n",
    "    plt.xlabel(kmeans_var.columns[i])\n",
    "    plt.ylabel(\"countMissions\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0,len(kmeans_var.columns)):\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "plt.scatter(\n",
    "    kmeans_var_array[y_kmeans4 == 0, 0], kmeans_var_array[y_kmeans4 == 0, 1],\n",
    "    s=200, c='lightgreen',\n",
    "    marker='s', edgecolor='black',\n",
    "    label='cluster 0'\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    kmeans_var_array[y_kmeans4 == 1, 0], kmeans_var_array[y_kmeans4 == 1, 1],\n",
    "    s=200, c='orange',\n",
    "    marker='o', edgecolor='black',\n",
    "    label='cluster 1'\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    kmeans_var_array[y_kmeans4 == 2, 0], kmeans_var_array[y_kmeans4 == 2, 1],\n",
    "    s=200, c='lightblue',\n",
    "    marker='v', edgecolor='black',\n",
    "    label='cluster 2'\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    kmeans_var_array[y_kmeans4 == 3, 0], kmeans_var_array[y_kmeans4 == 3, 1],\n",
    "    s=200, c='red',\n",
    "    marker='.', edgecolor='black',\n",
    "    label='cluster 3'\n",
    ")\n",
    "\n",
    "#    plot the centroids\n",
    "plt.scatter(\n",
    "    kmeans4.cluster_centers_[:, 0], kmeans4.cluster_centers_[:, 1],\n",
    "    s=700, marker='*',\n",
    "    c='red', edgecolor='black',\n",
    "    label='centroids'\n",
    ")\n",
    "plt.legend(scatterpoints=1,fontsize=20)\n",
    "plt.xlabel(kmeans_var.columns[0],fontsize=20)\n",
    "plt.ylabel(\"Total Missions\",fontsize=20)\n",
    "plt.title(\"Total Missions vs Total Mission Time\", fontsize=30)\n",
    "plt.xticks(fontsize=20, rotation=0)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "fig.savefig(\"CountMissions_MissionTime.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 16))\n",
    "plt.scatter(\n",
    "    kmeans_var_array[y_kmeans4 == 0, 2], kmeans_var_array[y_kmeans4 == 0, 1],\n",
    "    s=200, c='lightgreen',\n",
    "    marker='s', edgecolor='black',\n",
    "    label='cluster 0'\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    kmeans_var_array[y_kmeans4 == 1, 2], kmeans_var_array[y_kmeans4 == 1, 1],\n",
    "    s=200, c='orange',\n",
    "    marker='o', edgecolor='black',\n",
    "    label='cluster 1'\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    kmeans_var_array[y_kmeans4 == 2, 2], kmeans_var_array[y_kmeans4 == 2, 1],\n",
    "    s=200, c='lightblue',\n",
    "    marker='v', edgecolor='black',\n",
    "    label='cluster 2'\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    kmeans_var_array[y_kmeans4 == 3, 2], kmeans_var_array[y_kmeans4 == 3, 1],\n",
    "    s=200, c='yellow',\n",
    "    marker='.', edgecolor='black',\n",
    "    label='cluster 3'\n",
    ")\n",
    "\n",
    "#    plot the centroids\n",
    "plt.scatter(\n",
    "    kmeans4.cluster_centers_[:, 2], kmeans4.cluster_centers_[:, 1],\n",
    "    s=3000, marker='*',\n",
    "    c='red', edgecolor='black',\n",
    "    label='centroids'\n",
    ")\n",
    "\n",
    "    \n",
    "plt.legend(scatterpoints=1,fontsize=20)\n",
    "plt.xlabel(kmeans_var.columns[2],fontsize=20)\n",
    "plt.ylabel(\"Total Missions\",fontsize=20)\n",
    "plt.title(\"Total Missions vs Total Daily Mission Time\", fontsize=30)\n",
    "plt.xticks(fontsize=20, rotation=0)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "fig.savefig(\"CountMissions_DailyMissionTime.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 16))\n",
    "plt.scatter(\n",
    "    kmeans_var_array[y_kmeans4 == 0, 4], kmeans_var_array[y_kmeans4 == 0, 1],\n",
    "    s=200, c='lightgreen',\n",
    "    marker='s', edgecolor='black',\n",
    "    label='cluster 0'\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    kmeans_var_array[y_kmeans4 == 1, 4], kmeans_var_array[y_kmeans4 == 1, 1],\n",
    "    s=200, c='orange',\n",
    "    marker='o', edgecolor='black',\n",
    "    label='cluster 1'\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    kmeans_var_array[y_kmeans4 == 2, 4], kmeans_var_array[y_kmeans4 == 2, 1],\n",
    "    s=200, c='lightblue',\n",
    "    marker='v', edgecolor='black',\n",
    "    label='cluster 2'\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    kmeans_var_array[y_kmeans4 == 3, 4], kmeans_var_array[y_kmeans4 == 3, 1],\n",
    "    s=200, c='red',\n",
    "    marker='.', edgecolor='black',\n",
    "    label='cluster 3'\n",
    ")\n",
    "\n",
    "#    plot the centroids\n",
    "plt.scatter(\n",
    "    kmeans4.cluster_centers_[:, 4], kmeans4.cluster_centers_[:, 1],\n",
    "    s=700, marker='*',\n",
    "    c='red', edgecolor='black',\n",
    "    label='centroids'\n",
    ")\n",
    "plt.legend(scatterpoints=1,fontsize=20)\n",
    "plt.xlabel(kmeans_var.columns[4],fontsize=20)\n",
    "plt.ylabel(\"Total Missions\",fontsize=20)\n",
    "plt.title(\"Total Missions vs. Total Hint Used\", fontsize=30)\n",
    "plt.xticks(fontsize=20, rotation=0)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "fig.savefig(\"CountMissions_TotalHint.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 16))\n",
    "plt.scatter(\n",
    "    kmeans_var_array[y_kmeans4 == 0, 8], kmeans_var_array[y_kmeans4 == 0, 1],\n",
    "    s=200, c='lightgreen',\n",
    "    marker='s', edgecolor='black',\n",
    "    label='cluster 0'\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    kmeans_var_array[y_kmeans4 == 1, 8], kmeans_var_array[y_kmeans4 == 1, 1],\n",
    "    s=200, c='orange',\n",
    "    marker='o', edgecolor='black',\n",
    "    label='cluster 1'\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    kmeans_var_array[y_kmeans4 == 2, 8], kmeans_var_array[y_kmeans4 == 2, 1],\n",
    "    s=200, c='lightblue',\n",
    "    marker='v', edgecolor='black',\n",
    "    label='cluster 2'\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    kmeans_var_array[y_kmeans4 == 3, 8], kmeans_var_array[y_kmeans4 == 3, 1],\n",
    "    s=200, c='red',\n",
    "    marker='.', edgecolor='black',\n",
    "    label='cluster 3'\n",
    ")\n",
    "\n",
    "#    plot the centroids\n",
    "plt.scatter(\n",
    "    kmeans4.cluster_centers_[:, 8], kmeans4.cluster_centers_[:, 1],\n",
    "    s=700, marker='*',\n",
    "    c='red', edgecolor='black',\n",
    "    label='centroids'\n",
    ")\n",
    "plt.legend(scatterpoints=1,fontsize=20)\n",
    "plt.xlabel(kmeans_var.columns[8],fontsize=20)\n",
    "plt.ylabel(\"Total Missions\",fontsize=20)\n",
    "plt.title(\"Total Missions vs Total Duplicated Words\", fontsize=30)\n",
    "plt.xticks(fontsize=20, rotation=0)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_var['cluster'] = y_kmeans4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(kmeans_var[(kmeans_var['cluster'] == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(kmeans_var[(kmeans_var['cluster'] == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(kmeans_var[(kmeans_var['cluster'] == 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(kmeans_var[(kmeans_var['cluster'] == 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_var.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removeAds_cluster = kmeans_var.loc[kmeans_var.index.intersection(set(removeAds_players.index))]\n",
    "removeAds_cluster.head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 16))\n",
    "removeAds_cluster['cluster'].value_counts().sort_index().plot(kind = 'bar');\n",
    "plt.xlabel(\"Cluster\", fontsize=30)\n",
    "plt.ylabel(\"Total number of players\", fontsize=30)\n",
    "plt.title(\"Number of Ad Removal Purchasers by Cluster\", fontsize=40)\n",
    "plt.xticks(fontsize=30, rotation=0)\n",
    "plt.yticks(fontsize=30)\n",
    "fig.savefig(\"Num_players_bar.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster0 = var.loc[kmeans_var[(kmeans_var['cluster'] == 0)].index,:]\n",
    "cluster1 = var.loc[kmeans_var[(kmeans_var['cluster'] == 1)].index,:]\n",
    "cluster2 = var.loc[kmeans_var[(kmeans_var['cluster'] == 2)].index,:]\n",
    "cluster3 = var.loc[kmeans_var[(kmeans_var['cluster'] == 3)].index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Day20_adRev=total_result[30][['userID','ad_Rev']]\n",
    "kmeans_var['userID']=kmeans_var.index\n",
    "cluster_info=kmeans_var[['userID','cluster']]\n",
    "cluster_revenue=pd.merge(kmeans_var['cluster'],Day20_adRev, on='userID',how='left')\n",
    "\n",
    "fig = plt.figure()\n",
    "cluster_revenue.boxplot(by ='cluster', column =['ad_Rev'], figsize=(12,8)) \n",
    "plt.xlabel(\"Cluster\", fontsize=15)\n",
    "plt.ylabel(\"Ad Revenue\", fontsize=15)\n",
    "plt.title(\"Ad Revenue by Cluster\", fontsize=20)\n",
    "plt.xticks(fontsize=15, rotation=0)\n",
    "plt.yticks(fontsize=15)\n",
    "fig.savefig(\"AdRev_boxplot.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Day20_adRev=total_result[7][['userID','ad_Rev']]\n",
    "kmeans_var['userID']=kmeans_var.index\n",
    "cluster_info=kmeans_var[['userID','cluster']]\n",
    "cluster_revenue=pd.merge(kmeans_var['cluster'],Day20_adRev, on='userID',how='left')\n",
    "cluster_revenue.boxplot(by ='cluster', column =['ad_Rev'],  figsize=(12,8)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_indices0 = [i for i in cluster0.index if i not in removeAds_players.index]\n",
    "cluster0.loc[desired_indices0,:][['Lifespan','userLevel','CountMission','ad_Rev', 'adImpression_Rev', 'videoOffer_Rev','dailyMissionTime']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_indices1 = [i for i in cluster1.index if i not in removeAds_players.index]\n",
    "cluster1.loc[desired_indices1,:][['Lifespan','userLevel','CountMission','ad_Rev', 'adImpression_Rev', 'videoOffer_Rev','dailyMissionTime']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_indices2 = [i for i in cluster2.index if i not in removeAds_players.index]\n",
    "cluster2.loc[desired_indices2,:][['userLevel','CountMission','ad_Rev', 'adImpression_Rev', 'videoOffer_Rev','dailyMissionTime']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_indices3 = [i for i in cluster3.index if i not in removeAds_players.index]\n",
    "cluster3.loc[desired_indices3,:][['userLevel','CountMission','ad_Rev', 'adImpression_Rev', 'videoOffer_Rev','dailyMissionTime']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize each cluster using data from day 0 to day 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day30 = total_result[30]\n",
    "day30.set_index('userID', inplace = True)\n",
    "day30.dropna(axis=0, how='all', thresh=None, subset=None, inplace=True)\n",
    "\n",
    "day30 = day30.dropna(subset = ['gaUserAcquisitionChannel', 'platform'])\n",
    "day30.fillna(0 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day30.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day30_cluster0= day30.loc[cluster0.index,:]\n",
    "day30_cluster1= day30.loc[cluster1.index,:]\n",
    "day30_cluster2= day30.loc[cluster2.index,:]\n",
    "day30_cluster3= day30.loc[cluster3.index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day30_cluster0['ad_Rev'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day30_cluster1['ad_Rev'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day30_cluster2['ad_Rev'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day30_cluster3['ad_Rev'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression within each cluster to predict total ads value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['countAdImpression','countAdClicked','timePerMission', 'timePerDailyMission', 'hintsPerMission','dailyMissionTime', 'hintsPerLevel','duplicateWordsPerMis','extraWordsPerMis', 'invalidWordsPerMis','shufflesPerMission','countCVV', 'countNoCmplt', 'ad_Rev', 'adImpression_Rev', 'videoOffer_Rev']\n",
    "\n",
    "cls0_x = day7_cluster0.drop(columns=cols)\n",
    "cls0_x = pd.get_dummies(cls0_x, columns = ['gaUserAcquisitionChannel','platform'], prefix=['Chan', 'Plat'], drop_first=False)\n",
    "cls0_x = cls0_x.drop(columns='Plat_IOS')\n",
    "cls0_x = cls0_x.drop(columns = ['extraWords', 'invalidWords'])\n",
    "\n",
    "var_heatmap0 = cls0_x\n",
    "f, ax = plt.subplots(figsize=(30, 25))\n",
    "corr = var_heatmap0.corr()\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LassoCV on cluster 0\n",
    "cls0_x = preprocessing.normalize(cls0_x, norm='l2')\n",
    "cls0_y = day7_cluster0['ad_Rev'] \n",
    "\n",
    "x0_train, x0_test, y0_train, y0_test = train_test_split(cls0_x, cls0_y, test_size=0.2, random_state=42)\n",
    "reg_lcv = LassoCV(cv=5, random_state=0)\n",
    "cls0_reg_lcv = reg_lcv.fit(x0_train, y0_train)\n",
    "\n",
    "y0_test_predicted_lcv = cls0_reg_lcv.predict(x0_test)\n",
    "\n",
    "print('R-square: ', cls0_reg_lcv.score(x0_test, y0_test))\n",
    "print('MSE: ', mean_squared_error(y0_test,y0_test_predicted_lcv))\n",
    "print('Coeffcients: ', cls0_reg_lcv.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.arange(0.1, 1, 0.01)\n",
    "parameters = {'alpha': alpha}\n",
    "\n",
    "lml = linear_model.Lasso(normalize=False)\n",
    "\n",
    "clf = GridSearchCV(lml, parameters)\n",
    "print(clf.fit(x0_train, y0_train).best_params_['alpha'])\n",
    "cls0_lml = linear_model.Lasso(alpha = clf.fit(x0_train, y0_train).best_params_['alpha']).fit(x0_train, y0_train)\n",
    "\n",
    "\n",
    "y0_test_predicted_lml = clf.predict(x0_test)\n",
    "print(cls0_lml.score(x0_test, y0_test))\n",
    "print(mean_squared_error(y0_test,y0_test_predicted_lml))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls1_x = day7_cluster1.drop(columns=cols)\n",
    "cls1_x = pd.get_dummies(cls1_x, columns = ['gaUserAcquisitionChannel','platform'], prefix=['Chan', 'Plat'], drop_first=False)\n",
    "cls1_x = cls1_x.drop(columns = ['Plat_IOS','extraWords','invalidWords'])\n",
    "\n",
    "var_heatmap1 = cls1_x\n",
    "f, ax = plt.subplots(figsize=(20, 16))\n",
    "corr = var_heatmap1.corr()\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LassoCV on cluster 1\n",
    "cls1_x = preprocessing.normalize(cls1_x, norm='l2')\n",
    "cls1_y = day7_cluster1['ad_Rev'] \n",
    "\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(cls1_x, cls1_y, test_size=0.2, random_state=42)\n",
    "\n",
    "reg_lcv = LassoCV(cv=5, random_state=0)\n",
    "cls1_reg_lcv = reg_lcv.fit(x1_train, y1_train)\n",
    "\n",
    "y1_test_predicted_lcv = cls1_reg_lcv.predict(x1_test)\n",
    "\n",
    "print('R-square:', cls1_reg_lcv.score(x1_test, y1_test))\n",
    "print('MSE:', mean_squared_error(y1_test,y1_test_predicted_lcv))\n",
    "print('Coeffcients: ', cls1_reg_lcv.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls2_x = day7_cluster2.drop(columns=cols)\n",
    "cls2_x = pd.get_dummies(cls2_x, columns = ['gaUserAcquisitionChannel','platform'], prefix=['Chan', 'Plat'], drop_first=False)\n",
    "cls2_x = cls2_x.drop(columns = ['Plat_IOS','extraWords','invalidWords'])\n",
    "\n",
    "var_heatmap2 = cls2_x\n",
    "f, ax = plt.subplots(figsize=(20, 16))\n",
    "corr = var_heatmap2.corr()\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LassoCV on cluster 2\n",
    "cls2_x = preprocessing.normalize(cls2_x, norm='l2')\n",
    "cls2_y = day7_cluster2['ad_Rev'] \n",
    "\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(cls2_x, cls2_y, test_size=0.2, random_state=42)\n",
    "\n",
    "reg_lcv = LassoCV(cv=5, random_state=0)\n",
    "cls2_reg_lcv = reg_lcv.fit(x2_train, y2_train)\n",
    "\n",
    "y2_test_predicted_lcv = cls2_reg_lcv.predict(x2_test)\n",
    "\n",
    "print('R-square:',cls2_reg_lcv.score(x2_test, y2_test))\n",
    "print('MSE:',mean_squared_error(y2_test,y2_test_predicted_lcv))\n",
    "print('Coeffcients: ', cls2_reg_lcv.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls3_x = day7_cluster3.drop(columns=cols)\n",
    "cls3_x = pd.get_dummies(cls3_x, columns = ['gaUserAcquisitionChannel','platform'], prefix=['Chan', 'Plat'], drop_first=False)\n",
    "cls3_x = cls3_x.drop(columns = 'Plat_IOS')\n",
    "cls3_x = cls3_x.drop(columns = ['extraWords','invalidWords','missionTime'])\n",
    "\n",
    "var_heatmap3 = cls3_x\n",
    "f, ax = plt.subplots(figsize=(20, 16))\n",
    "corr = var_heatmap3.corr()\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LassoCV on cluster 3\n",
    "cls3_x = preprocessing.normalize(cls3_x, norm='l2')\n",
    "cls3_y = day7_cluster3['ad_Rev'] \n",
    "x3_train, x3_test, y3_train, y3_test = train_test_split(cls3_x, cls3_y, test_size=0.2, random_state=42)\n",
    "\n",
    "reg_lcv = LassoCV(cv=5, random_state=0)\n",
    "cls3_reg_lcv = reg_lcv.fit(x3_train, y3_train)\n",
    "\n",
    "y3_test_predicted_lcv = cls3_reg_lcv.predict(x3_test)\n",
    "\n",
    "print('R-square',cls3_reg_lcv.score(x3_test, y3_test))\n",
    "print('MSE:', mean_squared_error(y3_test,y3_test_predicted_lcv))\n",
    "print('Coeffcients: ', cls3_reg_lcv.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Regression to predict total ads revenue within each cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.arange(1, 300, 1)\n",
    "parameters = {'n_neighbors': n}\n",
    "\n",
    "neigh = KNeighborsRegressor()\n",
    "\n",
    "knn_cv = GridSearchCV(neigh, parameters)\n",
    "print(knn_cv.fit(x0_train, y0_train).best_params_['n_neighbors'])\n",
    "cls0_neigh = KNeighborsRegressor(n_neighbors = knn_cv.fit(x0_train, y0_train).best_params_['n_neighbors']).fit(x0_train, y0_train)\n",
    "\n",
    "y0_test_predicted_knn = cls0_neigh.predict(x0_test)\n",
    "\n",
    "print('R-square:',cls0_neigh.score(x0_test, y0_test))\n",
    "print('MSE: ', mean_squared_error(y0_test,y0_test_predicted_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.arange(1, 100, 1)\n",
    "parameters = {'n_neighbors': n}\n",
    "\n",
    "neigh = KNeighborsRegressor()\n",
    "\n",
    "knn_cv = GridSearchCV(neigh, parameters)\n",
    "print(knn_cv.fit(x1_train, y1_train).best_params_['n_neighbors'])\n",
    "cls1_neigh = KNeighborsRegressor(n_neighbors = knn_cv.fit(x1_train, y1_train).best_params_['n_neighbors']).fit(x1_train, y1_train)\n",
    "\n",
    "y1_test_predicted_knn = cls1_neigh.predict(x1_test)\n",
    "\n",
    "print('R-square:',cls1_neigh.score(x1_test, y1_test))\n",
    "print('MSE: ', mean_squared_error(y1_test,y1_test_predicted_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.arange(1, 100, 1)\n",
    "parameters = {'n_neighbors': n}\n",
    "\n",
    "neigh = KNeighborsRegressor()\n",
    "\n",
    "knn_cv = GridSearchCV(neigh, parameters)\n",
    "print(knn_cv.fit(x2_train, y2_train).best_params_['n_neighbors'])\n",
    "cls2_neigh = KNeighborsRegressor(n_neighbors = knn_cv.fit(x2_train, y2_train).best_params_['n_neighbors']).fit(x2_train, y2_train)\n",
    "\n",
    "y2_test_predicted_knn = cls2_neigh.predict(x2_test)\n",
    "\n",
    "print('R-square:',cls2_neigh.score(x2_test, y2_test))\n",
    "print('MSE: ', mean_squared_error(y2_test,y2_test_predicted_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.arange(1, 100, 1)\n",
    "parameters = {'n_neighbors': n}\n",
    "\n",
    "neigh = KNeighborsRegressor()\n",
    "\n",
    "knn_cv = GridSearchCV(neigh, parameters)\n",
    "print(knn_cv.fit(x3_train, y3_train).best_params_['n_neighbors'])\n",
    "cls3_neigh = KNeighborsRegressor(n_neighbors = knn_cv.fit(x3_train, y3_train).best_params_['n_neighbors']).fit(x3_train, y3_train)\n",
    "\n",
    "y3_test_predicted_knn = cls3_neigh.predict(x3_test)\n",
    "\n",
    "print('R-square:',cls3_neigh.score(x3_test, y3_test))\n",
    "print('MSE: ', mean_squared_error(y3_test,y3_test_predicted_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
